{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/miniconda3/envs/jax/lib/python3.10/site-packages/jax/_src/api_util.py:183: SyntaxWarning: Jitted function has static_argnums=(3, 4), but only accepts 4 positional arguments. This warning will be replaced by an error after 2022-08-20 at the earliest.\n",
      "  warnings.warn(f\"Jitted function has {argnums_name}={argnums}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pol dataset, N=15000, d=26\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "from jax import jit, vmap\n",
    "from functools import partial\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import data\n",
    "from kernels import Matern12Kernel, Matern32Kernel, Matern52Kernel\n",
    "from models import ExactGPModel, SGDGPModel\n",
    "from utils import revert_z_score\n",
    "from eval_utils import RMSE\n",
    "\n",
    "data_train, data_test = data.get_dataset('pol', split=0, normalise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softminus(x):\n",
    "    return math.log(math.exp(x) - 1)\n",
    "\n",
    "import math\n",
    "signal_scale = math.sqrt(0.07279852032661438)\n",
    "length_scale = 1.88330865\n",
    "length_scale_ard = jnp.array([0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "   5.5808063,  5.1676707])\n",
    "noise_scale = math.sqrt(0.0007456933963112533)\n",
    "\n",
    "signal_scale_init = math.sqrt(math.log(2.))\n",
    "length_scale_init = jnp.arange(1., 27.)\n",
    "noise_scale_init = math.sqrt(math.log(2.))\n",
    "\n",
    "kernel_config = {\n",
    "    'signal_scale': signal_scale,\n",
    "    'length_scale': length_scale\n",
    "}\n",
    "\n",
    "kernel_config_ard = {\n",
    "    'signal_scale': signal_scale,\n",
    "    'length_scale': length_scale_ard\n",
    "}\n",
    "\n",
    "kernel_config_init = {\n",
    "    'signal_scale': signal_scale_init,\n",
    "    'length_scale': length_scale_init\n",
    "}\n",
    "\n",
    "kernel = Matern32Kernel(kernel_config=kernel_config_ard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_gp = ExactGPModel(noise_scale=noise_scale, kernel=kernel)\n",
    "\n",
    "exact_gp.compute_representer_weights(data_train)\n",
    "exact_pred_mean = exact_gp.predictive_mean(data_train, data_test)\n",
    "exact_pred_var = exact_gp.predictive_variance(data_train, data_test) + noise_scale ** 2\n",
    "exact_pred_std = jnp.sqrt(exact_pred_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,) (1500,) (1500,)\n",
      "0.089043215\n",
      "1.2229466\n"
     ]
    }
   ],
   "source": [
    "print(data_test.y.shape, exact_pred_mean.shape, exact_pred_std.shape)\n",
    "# loc = revert_z_score(exact_pred_mean, mu=data_train.mu_y, sigma=data_train.sigma_y)\n",
    "# scale = revert_z_score(exact_pred_std, mu=0., sigma=data_train.sigma_y)\n",
    "# y = revert_z_score(data_test.y, mu=data_train.mu_y, sigma=data_train.sigma_y)\n",
    "loc = exact_pred_mean\n",
    "scale = exact_pred_std\n",
    "y = data_test.y\n",
    "\n",
    "test_rmse = RMSE(y, loc)\n",
    "print(test_rmse)\n",
    "test_llh = jax.scipy.stats.norm.logpdf(y, loc, scale).mean()\n",
    "print(test_llh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m optim_key \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m123\u001b[39m)\n\u001b[1;32m     16\u001b[0m sgd_gp \u001b[39m=\u001b[39m SGDGPModel(noise_scale\u001b[39m=\u001b[39mnoise_scale, kernel\u001b[39m=\u001b[39mkernel)\n\u001b[0;32m---> 17\u001b[0m alpha, info \u001b[39m=\u001b[39m sgd_gp\u001b[39m.\u001b[39;49mcompute_representer_weights(\n\u001b[1;32m     18\u001b[0m     key\u001b[39m=\u001b[39;49moptim_key,\n\u001b[1;32m     19\u001b[0m     train_ds\u001b[39m=\u001b[39;49mdata_train,\n\u001b[1;32m     20\u001b[0m     test_ds\u001b[39m=\u001b[39;49mdata_test,\n\u001b[1;32m     21\u001b[0m     config\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mtrain_config,\n\u001b[1;32m     22\u001b[0m     metrics_list\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     23\u001b[0m     exact_metrics\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m sgd_pred_mean \u001b[39m=\u001b[39m sgd_gp\u001b[39m.\u001b[39mpredictive_mean(data_train, data_test)\n",
      "File \u001b[0;32m~/Code/scalable-gaussian-processes/scalable_gps/models.py:229\u001b[0m, in \u001b[0;36mSGDGPModel.compute_representer_weights\u001b[0;34m(self, key, train_ds, test_ds, config, metrics_list, metrics_prefix, exact_metrics)\u001b[0m\n\u001b[1;32m    226\u001b[0m alpha, alpha_polyak, opt_state \u001b[39m=\u001b[39m update_fn(alpha, alpha_polyak, idx, features, opt_state, target_tuple)\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m config\u001b[39m.\u001b[39meval_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 229\u001b[0m     eval_metrics \u001b[39m=\u001b[39m eval_fn(alpha_polyak, idx, features, target_tuple)\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m wandb\u001b[39m.\u001b[39mrun \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         wandb\u001b[39m.\u001b[39mlog({\u001b[39m*\u001b[39m\u001b[39m*\u001b[39meval_metrics, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m'\u001b[39m: i}})\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Code/scalable-gaussian-processes/scalable_gps/eval_utils.py:118\u001b[0m, in \u001b[0;36mget_eval_fn.<locals>._fn\u001b[0;34m(params, idx, features, target_tuple)\u001b[0m\n\u001b[1;32m    115\u001b[0m metrics_update_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m    117\u001b[0m \u001b[39m# TODO: dont return N_steps dicts\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics_list:\n\u001b[1;32m    119\u001b[0m     metrics_update_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetrics_prefix\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_metric(metric)\n\u001b[1;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m metrics_update_dict\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import ml_collections\n",
    "config = ml_collections.ConfigDict()\n",
    "config.train_config = ml_collections.ConfigDict()\n",
    "\n",
    "config.train_config.learning_rate = 1e-4\n",
    "config.train_config.momentum = 0.9\n",
    "config.train_config.polyak = 1e-1\n",
    "config.train_config.iterations = int(1e4)\n",
    "config.train_config.batch_size = 20\n",
    "config.train_config.eval_every = 100\n",
    "config.train_config.n_features_optim = 100\n",
    "config.train_config.recompute_features = True\n",
    "\n",
    "optim_key = jax.random.PRNGKey(123)\n",
    "\n",
    "sgd_gp = SGDGPModel(noise_scale=noise_scale, kernel=kernel)\n",
    "alpha, info = sgd_gp.compute_representer_weights(\n",
    "    key=optim_key,\n",
    "    train_ds=data_train,\n",
    "    test_ds=data_test,\n",
    "    config=config.train_config,\n",
    "    metrics_list=[],\n",
    "    exact_metrics=None\n",
    ")\n",
    "\n",
    "sgd_pred_mean = sgd_gp.predictive_mean(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pred_std = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_test.y.shape, sgd_pred_mean.shape, sgd_pred_std.shape)\n",
    "# loc = revert_z_score(sgd_pred_mean, mu=data_train.mu_y, sigma=data_train.sigma_y)\n",
    "# scale = revert_z_score(sgd_pred_std, mu=0., sigma=data_train.sigma_y)\n",
    "# y = revert_z_score(data_test.y, mu=data_train.mu_y, sigma=data_train.sigma_y)\n",
    "loc = sgd_pred_mean\n",
    "scale = sgd_pred_std\n",
    "y = data_test.y\n",
    "\n",
    "test_rmse = RMSE(y, loc)\n",
    "print(test_rmse)\n",
    "# test_llh = jax.scipy.stats.norm.logpdf(y, loc, scale).mean()\n",
    "# print(test_llh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
