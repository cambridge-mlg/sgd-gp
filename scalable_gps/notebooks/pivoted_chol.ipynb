{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Pivoted Cholesky\n",
    "\n",
    "- Without jax.lax.while_loop, since `m` decides the shape of different tensors, it is hard to use `jax.lax.while_loop` to implement pivoted Cholesky. One possibility is `jax.lax.dynamic_slice` but that also doesn't jit well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from functools import partial\n",
    "def pivoted_cholesky(kernel, x, max_rank, diag_rtol=1e-3, jitter=1e-3, name=None):\n",
    "    n = x.shape[0]\n",
    "    assert max_rank <= n\n",
    "\n",
    "    orig_error = kernel.get_signal_scale() ** 2 + jitter\n",
    "    print(f'orig_error: {orig_error}')\n",
    "    matrix_diag = orig_error * jnp.ones((n,))\n",
    "\n",
    "    m = 0\n",
    "    pchol = jnp.zeros((max_rank, n))\n",
    "    perm = jnp.arange(n)\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0))\n",
    "    def _body_fn(m, pchol, perm, matrix_diag):\n",
    "        maxi = jnp.argmax(matrix_diag[perm[m:]]) + m\n",
    "        maxval = matrix_diag[perm][maxi]\n",
    "\n",
    "        perm = perm.at[..., [m, maxi]].set(perm[..., [maxi, m]])\n",
    "\n",
    "        # TODO: Figure out where jitter gets added, only where row is computed for same index kernel_fn(i, i)\n",
    "        row = kernel.kernel_fn(x[perm[m]], x[perm[m + 1:]]).squeeze()\n",
    "\n",
    "        row -= jnp.sum(pchol[:m+1, perm[m + 1:]] * pchol[:m+1, perm[m:m+1]], axis=-2)\n",
    "        pivot = jnp.sqrt(maxval)\n",
    "        row /= pivot\n",
    "\n",
    "        row = jnp.concatenate([pivot[None], row], axis=-1)\n",
    "        matrix_diag = matrix_diag.at[perm[m:]].set(matrix_diag[perm[m:]] - row**2)\n",
    "\n",
    "        pchol = pchol.at[m, perm[m:]].set(row)\n",
    "        \n",
    "        return pchol, perm, matrix_diag\n",
    "\n",
    "    cond = True\n",
    "    while cond:\n",
    "        pchol, perm, matrix_diag = _body_fn(m, pchol, perm, matrix_diag)\n",
    "        m = m + 1\n",
    "        error = jnp.linalg.norm(matrix_diag, ord=1, axis=-1)\n",
    "        max_err = jnp.max(error / orig_error)\n",
    "        print(f'Iteration: {m}, error : {max_err}')\n",
    "        cond = (m < max_rank) and (max_err > diag_rtol)\n",
    "        \n",
    "    \n",
    "    pchol = jnp.swapaxes(pchol, -1, -2)\n",
    "    return pchol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_error: 0.16000000000000003\n",
      "Iteration: 1, error : 8086.99267578125\n",
      "Iteration: 2, error : 7220.5732421875\n",
      "Iteration: 3, error : 6691.69677734375\n",
      "Iteration: 4, error : 6668.92236328125\n",
      "Iteration: 5, error : 6666.6201171875\n",
      "Iteration: 6, error : 6578.4365234375\n",
      "Iteration: 7, error : 4671.46435546875\n",
      "Iteration: 8, error : 4666.80322265625\n",
      "Iteration: 9, error : 4537.4189453125\n",
      "Iteration: 10, error : 3460.97802734375\n",
      "Iteration: 11, error : 3444.007080078125\n",
      "Iteration: 12, error : 3119.874267578125\n",
      "Iteration: 13, error : 2284.379150390625\n",
      "Iteration: 14, error : 1137.1146240234375\n",
      "Iteration: 15, error : 1029.4822998046875\n",
      "Iteration: 16, error : 1024.9822998046875\n",
      "Iteration: 17, error : 581.0130004882812\n",
      "Iteration: 18, error : 524.5748291015625\n",
      "Iteration: 19, error : 514.0660400390625\n",
      "Iteration: 20, error : 513.4921875\n",
      "Iteration: 21, error : 364.0638427734375\n",
      "Iteration: 22, error : 356.0989990234375\n",
      "Iteration: 23, error : 249.79214477539062\n",
      "Iteration: 24, error : 249.14634704589844\n",
      "Iteration: 25, error : 99.09024810791016\n",
      "Iteration: 26, error : 54.858768463134766\n",
      "Iteration: 27, error : 22.445981979370117\n",
      "Iteration: 28, error : 22.1685848236084\n",
      "Iteration: 29, error : 19.88070297241211\n",
      "Iteration: 30, error : 12.209667205810547\n",
      "Iteration: 31, error : 5.500360012054443\n",
      "Iteration: 32, error : 4.9414591789245605\n",
      "Iteration: 33, error : 1.6112580299377441\n",
      "Iteration: 34, error : 0.7773202061653137\n",
      "Iteration: 35, error : 0.7189432382583618\n",
      "Iteration: 36, error : 0.5096346735954285\n",
      "Iteration: 37, error : 0.4881141185760498\n",
      "Iteration: 38, error : 0.1700378954410553\n",
      "Iteration: 39, error : 0.12243685871362686\n",
      "Iteration: 40, error : 0.09555979073047638\n",
      "Iteration: 41, error : 0.09378207474946976\n",
      "Iteration: 42, error : 0.048640940338373184\n",
      "Iteration: 43, error : 0.04808790981769562\n",
      "Iteration: 44, error : 0.010364500805735588\n",
      "Iteration: 45, error : 0.004597763996571302\n",
      "Iteration: 46, error : 0.0041216532699763775\n",
      "Iteration: 47, error : 0.004103523213416338\n",
      "Iteration: 48, error : 0.002386733889579773\n",
      "Iteration: 49, error : 0.0014905821299180388\n",
      "Iteration: 50, error : 0.0012824332807213068\n",
      "Iteration: 51, error : 0.0012638939078897238\n",
      "Iteration: 52, error : 0.0012664683163166046\n",
      "Iteration: 53, error : 0.0013136847410351038\n",
      "Iteration: 54, error : 0.0013536402257159352\n",
      "Iteration: 55, error : 0.0013549482682719827\n",
      "Iteration: 56, error : 0.0013756683329120278\n",
      "Iteration: 57, error : 0.0014293896965682507\n",
      "Iteration: 58, error : 0.0014459220692515373\n",
      "Iteration: 59, error : 0.0015217418549582362\n",
      "Iteration: 60, error : 0.0015944985207170248\n",
      "Iteration: 61, error : 0.0016000467585399747\n",
      "Iteration: 62, error : 0.0017155857058241963\n",
      "Iteration: 63, error : 0.001805997104384005\n",
      "Iteration: 64, error : 0.0018546321662142873\n",
      "Iteration: 65, error : 0.0018836903618648648\n",
      "Iteration: 66, error : 0.0019068702822551131\n",
      "Iteration: 67, error : 0.0020205730106681585\n",
      "Iteration: 68, error : 0.002021185355260968\n",
      "Iteration: 69, error : 0.002105162013322115\n",
      "Iteration: 70, error : 0.002111074747517705\n",
      "Iteration: 71, error : 0.0021212745923548937\n",
      "Iteration: 72, error : 0.0021242026705294847\n",
      "Iteration: 73, error : 0.0022333799861371517\n",
      "Iteration: 74, error : 0.0024581903126090765\n",
      "Iteration: 75, error : 0.002460383577272296\n",
      "Iteration: 76, error : 0.0024910112842917442\n",
      "Iteration: 77, error : 0.002661495702341199\n",
      "Iteration: 78, error : 0.0027017095126211643\n",
      "Iteration: 79, error : 0.0027265925891697407\n",
      "Iteration: 80, error : 0.0027817878872156143\n",
      "Iteration: 81, error : 0.0027829697355628014\n",
      "Iteration: 82, error : 0.002788472454994917\n",
      "Iteration: 83, error : 0.003045587334781885\n",
      "Iteration: 84, error : 0.0031786025501787663\n",
      "Iteration: 85, error : 0.0031830088701099157\n",
      "Iteration: 86, error : 0.003217292483896017\n",
      "Iteration: 87, error : 0.003316012676805258\n",
      "Iteration: 88, error : 0.003662235103547573\n",
      "Iteration: 89, error : 0.0037257650401443243\n",
      "Iteration: 90, error : 0.0037400582805275917\n",
      "Iteration: 91, error : 0.003948412369936705\n",
      "Iteration: 92, error : 0.00397829432040453\n",
      "Iteration: 93, error : 0.004022948443889618\n",
      "Iteration: 94, error : 0.004100628662854433\n",
      "Iteration: 95, error : 0.00427778996527195\n",
      "Iteration: 96, error : 0.00501850713044405\n",
      "Iteration: 97, error : 0.005648037418723106\n",
      "Iteration: 98, error : 0.006852549500763416\n",
      "Iteration: 99, error : 0.0075842151418328285\n",
      "Iteration: 100, error : 0.008948426693677902\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import tensorflow_probability as tfp\n",
    "import jax.numpy as jnp\n",
    "from kernels import Matern32Kernel, RBFKernel\n",
    "import numpy as np\n",
    "\n",
    "kernel = RBFKernel({'length_scale': jnp.array([0.3]), 'signal_scale': 0.4, 'noise_scale': 0.7})\n",
    "\n",
    "N, rank = 10000, 100\n",
    "jitter = 0.\n",
    "\n",
    "x = jax.random.normal(jax.random.PRNGKey(1), (N, 1))\n",
    "\n",
    "A = kernel.kernel_fn(x, x) + jitter * jnp.eye(N)\n",
    "\n",
    "Lk = jnp.array(tfp.math.pivoted_cholesky(np.array(A), rank))\n",
    "\n",
    "Lk_jax = pivoted_cholesky(kernel, x, rank, jitter=jitter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06732793\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.71050543e-20 ... -1.15539682e-04\n",
      "   1.08598848e-04  3.12456337e-04]\n",
      " ...\n",
      " [-2.58493941e-26  0.00000000e+00  0.00000000e+00 ...  1.03876140e-04\n",
      "  -1.15495066e-04 -1.09427077e-04]\n",
      " [-1.49011612e-08  1.77635684e-15  0.00000000e+00 ... -4.35540351e-05\n",
      "  -1.52960900e-04 -1.27421954e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.92492848e-06\n",
      "   1.05673236e-04  1.55344766e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(jnp.linalg.norm(Lk - Lk_jax))\n",
    "\n",
    "print(Lk - Lk_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnum3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
