{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-06 16:01:42.324373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-04-06 16:01:42.356741: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-06 16:01:43.101192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-04-06 16:01:43.101299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-04-06 16:01:43.101309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scalable_gps\n",
    "from scalable_gps.kernels import Matern32Kernel\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import gpytorch as gpt\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpflux\n",
    "# filepath = '/home/shreyaspadhy_gmail_com/scalable-gaussian-processes/scalable_gps/results/exact_gp_results/dataset_pol.evaltol_0.001.kernel_matern.loverank_200.lr_0.1.model_exact.numiter_100.seed_0.traintol_1.0.pkl'\n",
    "\n",
    "\n",
    "# with open(filepath, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yacht dataset, N=308, d=6\n",
      "(278, 6)\n",
      "noise :  tensor([0.6932], grad_fn=<AddBackward0>)\n",
      "ExactGPModel(\n",
      "  (likelihood): GaussianLikelihood(\n",
      "    (noise_covar): HomoskedasticNoise(\n",
      "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
      "    )\n",
      "  )\n",
      "  (mean_module): ConstantMean()\n",
      "  (covar_module): ScaleKernel(\n",
      "    (base_kernel): MaternKernel(\n",
      "      (raw_lengthscale_constraint): Positive()\n",
      "    )\n",
      "    (raw_outputscale_constraint): Positive()\n",
      "  )\n",
      ")\n",
      "MultivariateNormal(loc: torch.Size([30]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/_src/api_util.py:183: SyntaxWarning: Jitted function has static_argnums=(3, 4), but only accepts 4 positional arguments. This warning will be replaced by an error after 2022-08-20 at the earliest.\n",
      "  warnings.warn(f\"Jitted function has {argnums_name}={argnums}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1297213\n",
      "tensor(0.6141)\n",
      "Iter 1/500 - Loss: 1.137   noise: 0.693 output_scale: 0.693\n",
      "Iter 2/500 - Loss: 1.098   noise: 0.644 output_scale: 0.644\n",
      "Iter 3/500 - Loss: 1.059   noise: 0.598 output_scale: 0.599\n",
      "Iter 4/500 - Loss: 1.019   noise: 0.554 output_scale: 0.557\n",
      "Iter 5/500 - Loss: 0.979   noise: 0.513 output_scale: 0.521\n",
      "Iter 6/500 - Loss: 0.939   noise: 0.474 output_scale: 0.491\n",
      "Iter 7/500 - Loss: 0.898   noise: 0.437 output_scale: 0.468\n",
      "Iter 8/500 - Loss: 0.856   noise: 0.402 output_scale: 0.452\n",
      "Iter 9/500 - Loss: 0.814   noise: 0.370 output_scale: 0.443\n",
      "Iter 10/500 - Loss: 0.772   noise: 0.339 output_scale: 0.439\n",
      "Iter 11/500 - Loss: 0.729   noise: 0.311 output_scale: 0.439\n",
      "Iter 12/500 - Loss: 0.687   noise: 0.285 output_scale: 0.441\n",
      "Iter 13/500 - Loss: 0.644   noise: 0.260 output_scale: 0.444\n",
      "Iter 14/500 - Loss: 0.601   noise: 0.238 output_scale: 0.447\n",
      "Iter 15/500 - Loss: 0.558   noise: 0.217 output_scale: 0.448\n",
      "Iter 16/500 - Loss: 0.516   noise: 0.197 output_scale: 0.447\n",
      "Iter 17/500 - Loss: 0.473   noise: 0.180 output_scale: 0.443\n",
      "Iter 18/500 - Loss: 0.431   noise: 0.163 output_scale: 0.437\n",
      "Iter 19/500 - Loss: 0.388   noise: 0.148 output_scale: 0.428\n",
      "Iter 20/500 - Loss: 0.346   noise: 0.135 output_scale: 0.419\n",
      "Iter 21/500 - Loss: 0.304   noise: 0.122 output_scale: 0.408\n",
      "Iter 22/500 - Loss: 0.262   noise: 0.111 output_scale: 0.398\n",
      "Iter 23/500 - Loss: 0.221   noise: 0.100 output_scale: 0.389\n",
      "Iter 24/500 - Loss: 0.180   noise: 0.091 output_scale: 0.382\n",
      "Iter 25/500 - Loss: 0.139   noise: 0.082 output_scale: 0.376\n",
      "Iter 26/500 - Loss: 0.099   noise: 0.074 output_scale: 0.373\n",
      "Iter 27/500 - Loss: 0.059   noise: 0.067 output_scale: 0.372\n",
      "Iter 28/500 - Loss: 0.019   noise: 0.061 output_scale: 0.372\n",
      "Iter 29/500 - Loss: -0.020   noise: 0.055 output_scale: 0.372\n",
      "Iter 30/500 - Loss: -0.059   noise: 0.049 output_scale: 0.373\n",
      "Iter 31/500 - Loss: -0.097   noise: 0.045 output_scale: 0.373\n",
      "Iter 32/500 - Loss: -0.134   noise: 0.040 output_scale: 0.371\n",
      "Iter 33/500 - Loss: -0.171   noise: 0.036 output_scale: 0.367\n",
      "Iter 34/500 - Loss: -0.207   noise: 0.033 output_scale: 0.362\n",
      "Iter 35/500 - Loss: -0.242   noise: 0.030 output_scale: 0.355\n",
      "Iter 36/500 - Loss: -0.276   noise: 0.027 output_scale: 0.347\n",
      "Iter 37/500 - Loss: -0.310   noise: 0.024 output_scale: 0.339\n",
      "Iter 38/500 - Loss: -0.343   noise: 0.022 output_scale: 0.332\n",
      "Iter 39/500 - Loss: -0.374   noise: 0.020 output_scale: 0.327\n",
      "Iter 40/500 - Loss: -0.405   noise: 0.018 output_scale: 0.323\n",
      "Iter 41/500 - Loss: -0.435   noise: 0.017 output_scale: 0.322\n",
      "Iter 42/500 - Loss: -0.464   noise: 0.015 output_scale: 0.323\n",
      "Iter 43/500 - Loss: -0.492   noise: 0.014 output_scale: 0.325\n",
      "Iter 44/500 - Loss: -0.519   noise: 0.012 output_scale: 0.328\n",
      "Iter 45/500 - Loss: -0.545   noise: 0.011 output_scale: 0.331\n",
      "Iter 46/500 - Loss: -0.570   noise: 0.010 output_scale: 0.334\n",
      "Iter 47/500 - Loss: -0.594   noise: 0.009 output_scale: 0.337\n",
      "Iter 48/500 - Loss: -0.618   noise: 0.009 output_scale: 0.340\n",
      "Iter 49/500 - Loss: -0.640   noise: 0.008 output_scale: 0.343\n",
      "Iter 50/500 - Loss: -0.662   noise: 0.007 output_scale: 0.348\n",
      "Iter 51/500 - Loss: -0.682   noise: 0.007 output_scale: 0.355\n",
      "Iter 52/500 - Loss: -0.702   noise: 0.006 output_scale: 0.364\n",
      "Iter 53/500 - Loss: -0.721   noise: 0.006 output_scale: 0.375\n",
      "Iter 54/500 - Loss: -0.739   noise: 0.005 output_scale: 0.388\n",
      "Iter 55/500 - Loss: -0.756   noise: 0.005 output_scale: 0.403\n",
      "Iter 56/500 - Loss: -0.773   noise: 0.004 output_scale: 0.418\n",
      "Iter 57/500 - Loss: -0.789   noise: 0.004 output_scale: 0.434\n",
      "Iter 58/500 - Loss: -0.804   noise: 0.004 output_scale: 0.450\n",
      "Iter 59/500 - Loss: -0.818   noise: 0.004 output_scale: 0.466\n",
      "Iter 60/500 - Loss: -0.832   noise: 0.003 output_scale: 0.483\n",
      "Iter 61/500 - Loss: -0.845   noise: 0.003 output_scale: 0.500\n",
      "Iter 62/500 - Loss: -0.857   noise: 0.003 output_scale: 0.519\n",
      "Iter 63/500 - Loss: -0.869   noise: 0.003 output_scale: 0.539\n",
      "Iter 64/500 - Loss: -0.880   noise: 0.003 output_scale: 0.561\n",
      "Iter 65/500 - Loss: -0.891   noise: 0.002 output_scale: 0.583\n",
      "Iter 66/500 - Loss: -0.901   noise: 0.002 output_scale: 0.606\n",
      "Iter 67/500 - Loss: -0.910   noise: 0.002 output_scale: 0.629\n",
      "Iter 68/500 - Loss: -0.919   noise: 0.002 output_scale: 0.651\n",
      "Iter 69/500 - Loss: -0.927   noise: 0.002 output_scale: 0.673\n",
      "Iter 70/500 - Loss: -0.935   noise: 0.002 output_scale: 0.694\n",
      "Iter 71/500 - Loss: -0.943   noise: 0.002 output_scale: 0.714\n",
      "Iter 72/500 - Loss: -0.950   noise: 0.002 output_scale: 0.734\n",
      "Iter 73/500 - Loss: -0.957   noise: 0.002 output_scale: 0.754\n",
      "Iter 74/500 - Loss: -0.963   noise: 0.001 output_scale: 0.774\n",
      "Iter 75/500 - Loss: -0.969   noise: 0.001 output_scale: 0.794\n",
      "Iter 76/500 - Loss: -0.975   noise: 0.001 output_scale: 0.813\n",
      "Iter 77/500 - Loss: -0.980   noise: 0.001 output_scale: 0.833\n",
      "Iter 78/500 - Loss: -0.986   noise: 0.001 output_scale: 0.851\n",
      "Iter 79/500 - Loss: -0.990   noise: 0.001 output_scale: 0.869\n",
      "Iter 80/500 - Loss: -0.995   noise: 0.001 output_scale: 0.885\n",
      "Iter 81/500 - Loss: -0.999   noise: 0.001 output_scale: 0.900\n",
      "Iter 82/500 - Loss: -1.004   noise: 0.001 output_scale: 0.915\n",
      "Iter 83/500 - Loss: -1.008   noise: 0.001 output_scale: 0.930\n",
      "Iter 84/500 - Loss: -1.011   noise: 0.001 output_scale: 0.944\n",
      "Iter 85/500 - Loss: -1.015   noise: 0.001 output_scale: 0.959\n",
      "Iter 86/500 - Loss: -1.018   noise: 0.001 output_scale: 0.974\n",
      "Iter 87/500 - Loss: -1.022   noise: 0.001 output_scale: 0.988\n",
      "Iter 88/500 - Loss: -1.025   noise: 0.001 output_scale: 1.003\n",
      "Iter 89/500 - Loss: -1.028   noise: 0.001 output_scale: 1.017\n",
      "Iter 90/500 - Loss: -1.031   noise: 0.001 output_scale: 1.030\n",
      "Iter 91/500 - Loss: -1.033   noise: 0.001 output_scale: 1.043\n",
      "Iter 92/500 - Loss: -1.036   noise: 0.001 output_scale: 1.056\n",
      "Iter 93/500 - Loss: -1.039   noise: 0.001 output_scale: 1.069\n",
      "Iter 94/500 - Loss: -1.041   noise: 0.001 output_scale: 1.082\n",
      "Iter 95/500 - Loss: -1.043   noise: 0.001 output_scale: 1.096\n",
      "Iter 96/500 - Loss: -1.045   noise: 0.001 output_scale: 1.110\n",
      "Iter 97/500 - Loss: -1.048   noise: 0.001 output_scale: 1.124\n",
      "Iter 98/500 - Loss: -1.050   noise: 0.001 output_scale: 1.139\n",
      "Iter 99/500 - Loss: -1.052   noise: 0.001 output_scale: 1.153\n",
      "Iter 100/500 - Loss: -1.053   noise: 0.001 output_scale: 1.168\n",
      "Iter 101/500 - Loss: -1.055   noise: 0.001 output_scale: 1.182\n",
      "Iter 102/500 - Loss: -1.057   noise: 0.001 output_scale: 1.196\n",
      "Iter 103/500 - Loss: -1.059   noise: 0.001 output_scale: 1.210\n",
      "Iter 104/500 - Loss: -1.060   noise: 0.001 output_scale: 1.224\n",
      "Iter 105/500 - Loss: -1.062   noise: 0.001 output_scale: 1.239\n",
      "Iter 106/500 - Loss: -1.063   noise: 0.001 output_scale: 1.254\n",
      "Iter 107/500 - Loss: -1.065   noise: 0.001 output_scale: 1.269\n",
      "Iter 108/500 - Loss: -1.066   noise: 0.001 output_scale: 1.284\n",
      "Iter 109/500 - Loss: -1.068   noise: 0.001 output_scale: 1.299\n",
      "Iter 110/500 - Loss: -1.069   noise: 0.001 output_scale: 1.314\n",
      "Iter 111/500 - Loss: -1.070   noise: 0.000 output_scale: 1.329\n",
      "Iter 112/500 - Loss: -1.071   noise: 0.000 output_scale: 1.343\n",
      "Iter 113/500 - Loss: -1.073   noise: 0.000 output_scale: 1.358\n",
      "Iter 114/500 - Loss: -1.074   noise: 0.000 output_scale: 1.372\n",
      "Iter 115/500 - Loss: -1.075   noise: 0.000 output_scale: 1.386\n",
      "Iter 116/500 - Loss: -1.076   noise: 0.000 output_scale: 1.400\n",
      "Iter 117/500 - Loss: -1.077   noise: 0.000 output_scale: 1.414\n",
      "Iter 118/500 - Loss: -1.078   noise: 0.000 output_scale: 1.428\n",
      "Iter 119/500 - Loss: -1.079   noise: 0.000 output_scale: 1.442\n",
      "Iter 120/500 - Loss: -1.080   noise: 0.000 output_scale: 1.456\n",
      "Iter 121/500 - Loss: -1.081   noise: 0.000 output_scale: 1.470\n",
      "Iter 122/500 - Loss: -1.082   noise: 0.000 output_scale: 1.484\n",
      "Iter 123/500 - Loss: -1.083   noise: 0.000 output_scale: 1.497\n",
      "Iter 124/500 - Loss: -1.084   noise: 0.000 output_scale: 1.510\n",
      "Iter 125/500 - Loss: -1.085   noise: 0.000 output_scale: 1.523\n",
      "Iter 126/500 - Loss: -1.086   noise: 0.000 output_scale: 1.535\n",
      "Iter 127/500 - Loss: -1.087   noise: 0.000 output_scale: 1.548\n",
      "Iter 128/500 - Loss: -1.088   noise: 0.000 output_scale: 1.560\n",
      "Iter 129/500 - Loss: -1.089   noise: 0.000 output_scale: 1.573\n",
      "Iter 130/500 - Loss: -1.089   noise: 0.000 output_scale: 1.585\n",
      "Iter 131/500 - Loss: -1.090   noise: 0.000 output_scale: 1.598\n",
      "Iter 132/500 - Loss: -1.091   noise: 0.000 output_scale: 1.611\n",
      "Iter 133/500 - Loss: -1.092   noise: 0.000 output_scale: 1.624\n",
      "Iter 134/500 - Loss: -1.093   noise: 0.000 output_scale: 1.636\n",
      "Iter 135/500 - Loss: -1.093   noise: 0.000 output_scale: 1.648\n",
      "Iter 136/500 - Loss: -1.094   noise: 0.000 output_scale: 1.659\n",
      "Iter 137/500 - Loss: -1.094   noise: 0.000 output_scale: 1.671\n",
      "Iter 138/500 - Loss: -1.095   noise: 0.000 output_scale: 1.683\n",
      "Iter 139/500 - Loss: -1.096   noise: 0.000 output_scale: 1.696\n",
      "Iter 140/500 - Loss: -1.097   noise: 0.000 output_scale: 1.708\n",
      "Iter 141/500 - Loss: -1.097   noise: 0.000 output_scale: 1.721\n",
      "Iter 142/500 - Loss: -1.098   noise: 0.000 output_scale: 1.733\n",
      "Iter 143/500 - Loss: -1.099   noise: 0.000 output_scale: 1.746\n",
      "Iter 144/500 - Loss: -1.099   noise: 0.000 output_scale: 1.758\n",
      "Iter 145/500 - Loss: -1.100   noise: 0.000 output_scale: 1.770\n",
      "Iter 146/500 - Loss: -1.100   noise: 0.000 output_scale: 1.781\n",
      "Iter 147/500 - Loss: -1.101   noise: 0.000 output_scale: 1.793\n",
      "Iter 148/500 - Loss: -1.102   noise: 0.000 output_scale: 1.806\n",
      "Iter 149/500 - Loss: -1.102   noise: 0.000 output_scale: 1.818\n",
      "Iter 150/500 - Loss: -1.103   noise: 0.000 output_scale: 1.831\n",
      "Iter 151/500 - Loss: -1.103   noise: 0.000 output_scale: 1.844\n",
      "Iter 152/500 - Loss: -1.104   noise: 0.000 output_scale: 1.856\n",
      "Iter 153/500 - Loss: -1.104   noise: 0.000 output_scale: 1.868\n",
      "Iter 154/500 - Loss: -1.105   noise: 0.000 output_scale: 1.881\n",
      "Iter 155/500 - Loss: -1.105   noise: 0.000 output_scale: 1.893\n",
      "Iter 156/500 - Loss: -1.106   noise: 0.000 output_scale: 1.905\n",
      "Iter 157/500 - Loss: -1.106   noise: 0.000 output_scale: 1.917\n",
      "Iter 158/500 - Loss: -1.106   noise: 0.000 output_scale: 1.929\n",
      "Iter 159/500 - Loss: -1.107   noise: 0.000 output_scale: 1.942\n",
      "Iter 160/500 - Loss: -1.108   noise: 0.000 output_scale: 1.954\n",
      "Iter 161/500 - Loss: -1.108   noise: 0.000 output_scale: 1.966\n",
      "Iter 162/500 - Loss: -1.109   noise: 0.000 output_scale: 1.978\n",
      "Iter 163/500 - Loss: -1.109   noise: 0.000 output_scale: 1.989\n",
      "Iter 164/500 - Loss: -1.110   noise: 0.000 output_scale: 2.001\n",
      "Iter 165/500 - Loss: -1.110   noise: 0.000 output_scale: 2.012\n",
      "Iter 166/500 - Loss: -1.110   noise: 0.000 output_scale: 2.025\n",
      "Iter 167/500 - Loss: -1.111   noise: 0.000 output_scale: 2.037\n",
      "Iter 168/500 - Loss: -1.111   noise: 0.000 output_scale: 2.050\n",
      "Iter 169/500 - Loss: -1.112   noise: 0.000 output_scale: 2.062\n",
      "Iter 170/500 - Loss: -1.112   noise: 0.000 output_scale: 2.074\n",
      "Iter 171/500 - Loss: -1.113   noise: 0.000 output_scale: 2.086\n",
      "Iter 172/500 - Loss: -1.113   noise: 0.000 output_scale: 2.097\n",
      "Iter 173/500 - Loss: -1.113   noise: 0.000 output_scale: 2.108\n",
      "Iter 174/500 - Loss: -1.114   noise: 0.000 output_scale: 2.119\n",
      "Iter 175/500 - Loss: -1.114   noise: 0.000 output_scale: 2.131\n",
      "Iter 176/500 - Loss: -1.115   noise: 0.000 output_scale: 2.143\n",
      "Iter 177/500 - Loss: -1.115   noise: 0.000 output_scale: 2.154\n",
      "Iter 178/500 - Loss: -1.115   noise: 0.000 output_scale: 2.166\n",
      "Iter 179/500 - Loss: -1.116   noise: 0.000 output_scale: 2.178\n",
      "Iter 180/500 - Loss: -1.116   noise: 0.000 output_scale: 2.190\n",
      "Iter 181/500 - Loss: -1.117   noise: 0.000 output_scale: 2.202\n",
      "Iter 182/500 - Loss: -1.117   noise: 0.000 output_scale: 2.214\n",
      "Iter 183/500 - Loss: -1.117   noise: 0.000 output_scale: 2.225\n",
      "Iter 184/500 - Loss: -1.118   noise: 0.000 output_scale: 2.237\n",
      "Iter 185/500 - Loss: -1.118   noise: 0.000 output_scale: 2.248\n",
      "Iter 186/500 - Loss: -1.118   noise: 0.000 output_scale: 2.260\n",
      "Iter 187/500 - Loss: -1.119   noise: 0.000 output_scale: 2.272\n",
      "Iter 188/500 - Loss: -1.119   noise: 0.000 output_scale: 2.285\n",
      "Iter 189/500 - Loss: -1.119   noise: 0.000 output_scale: 2.297\n",
      "Iter 190/500 - Loss: -1.120   noise: 0.000 output_scale: 2.308\n",
      "Iter 191/500 - Loss: -1.120   noise: 0.000 output_scale: 2.320\n",
      "Iter 192/500 - Loss: -1.120   noise: 0.000 output_scale: 2.331\n",
      "Iter 193/500 - Loss: -1.121   noise: 0.000 output_scale: 2.342\n",
      "Iter 194/500 - Loss: -1.121   noise: 0.000 output_scale: 2.353\n",
      "Iter 195/500 - Loss: -1.122   noise: 0.000 output_scale: 2.364\n",
      "Iter 196/500 - Loss: -1.122   noise: 0.000 output_scale: 2.376\n",
      "Iter 197/500 - Loss: -1.122   noise: 0.000 output_scale: 2.388\n",
      "Iter 198/500 - Loss: -1.122   noise: 0.000 output_scale: 2.401\n",
      "Iter 199/500 - Loss: -1.123   noise: 0.000 output_scale: 2.413\n",
      "Iter 200/500 - Loss: -1.123   noise: 0.000 output_scale: 2.425\n",
      "Iter 201/500 - Loss: -1.123   noise: 0.000 output_scale: 2.436\n",
      "Iter 202/500 - Loss: -1.123   noise: 0.000 output_scale: 2.448\n",
      "Iter 203/500 - Loss: -1.124   noise: 0.000 output_scale: 2.459\n",
      "Iter 204/500 - Loss: -1.124   noise: 0.000 output_scale: 2.470\n",
      "Iter 205/500 - Loss: -1.124   noise: 0.000 output_scale: 2.481\n",
      "Iter 206/500 - Loss: -1.124   noise: 0.000 output_scale: 2.492\n",
      "Iter 207/500 - Loss: -1.125   noise: 0.000 output_scale: 2.503\n",
      "Iter 208/500 - Loss: -1.125   noise: 0.000 output_scale: 2.515\n",
      "Iter 209/500 - Loss: -1.126   noise: 0.000 output_scale: 2.527\n",
      "Iter 210/500 - Loss: -1.126   noise: 0.000 output_scale: 2.539\n",
      "Iter 211/500 - Loss: -1.126   noise: 0.000 output_scale: 2.551\n",
      "Iter 212/500 - Loss: -1.126   noise: 0.000 output_scale: 2.563\n",
      "Iter 213/500 - Loss: -1.126   noise: 0.000 output_scale: 2.575\n",
      "Iter 214/500 - Loss: -1.127   noise: 0.000 output_scale: 2.587\n",
      "Iter 215/500 - Loss: -1.127   noise: 0.000 output_scale: 2.598\n",
      "Iter 216/500 - Loss: -1.127   noise: 0.000 output_scale: 2.608\n",
      "Iter 217/500 - Loss: -1.128   noise: 0.000 output_scale: 2.618\n",
      "Iter 218/500 - Loss: -1.128   noise: 0.000 output_scale: 2.628\n",
      "Iter 219/500 - Loss: -1.128   noise: 0.000 output_scale: 2.638\n",
      "Iter 220/500 - Loss: -1.128   noise: 0.000 output_scale: 2.649\n",
      "Iter 221/500 - Loss: -1.128   noise: 0.000 output_scale: 2.660\n",
      "Iter 222/500 - Loss: -1.129   noise: 0.000 output_scale: 2.674\n",
      "Iter 223/500 - Loss: -1.129   noise: 0.000 output_scale: 2.687\n",
      "Iter 224/500 - Loss: -1.130   noise: 0.000 output_scale: 2.700\n",
      "Iter 225/500 - Loss: -1.130   noise: 0.000 output_scale: 2.712\n",
      "Iter 226/500 - Loss: -1.130   noise: 0.000 output_scale: 2.724\n",
      "Iter 227/500 - Loss: -1.130   noise: 0.000 output_scale: 2.734\n",
      "Iter 228/500 - Loss: -1.130   noise: 0.000 output_scale: 2.744\n",
      "Iter 229/500 - Loss: -1.130   noise: 0.000 output_scale: 2.754\n",
      "Iter 230/500 - Loss: -1.131   noise: 0.000 output_scale: 2.764\n",
      "Iter 231/500 - Loss: -1.131   noise: 0.000 output_scale: 2.776\n",
      "Iter 232/500 - Loss: -1.131   noise: 0.000 output_scale: 2.789\n",
      "Iter 233/500 - Loss: -1.132   noise: 0.000 output_scale: 2.803\n",
      "Iter 234/500 - Loss: -1.132   noise: 0.000 output_scale: 2.816\n",
      "Iter 235/500 - Loss: -1.132   noise: 0.000 output_scale: 2.829\n",
      "Iter 236/500 - Loss: -1.132   noise: 0.000 output_scale: 2.842\n",
      "Iter 237/500 - Loss: -1.132   noise: 0.000 output_scale: 2.854\n",
      "Iter 238/500 - Loss: -1.132   noise: 0.000 output_scale: 2.865\n",
      "Iter 239/500 - Loss: -1.132   noise: 0.000 output_scale: 2.876\n",
      "Iter 240/500 - Loss: -1.133   noise: 0.000 output_scale: 2.887\n",
      "Iter 241/500 - Loss: -1.133   noise: 0.000 output_scale: 2.898\n",
      "Iter 242/500 - Loss: -1.133   noise: 0.000 output_scale: 2.910\n",
      "Iter 243/500 - Loss: -1.134   noise: 0.000 output_scale: 2.921\n",
      "Iter 244/500 - Loss: -1.133   noise: 0.000 output_scale: 2.933\n",
      "Iter 245/500 - Loss: -1.134   noise: 0.000 output_scale: 2.945\n",
      "Iter 246/500 - Loss: -1.134   noise: 0.000 output_scale: 2.958\n",
      "Iter 247/500 - Loss: -1.134   noise: 0.000 output_scale: 2.971\n",
      "Iter 248/500 - Loss: -1.134   noise: 0.000 output_scale: 2.983\n",
      "Iter 249/500 - Loss: -1.135   noise: 0.000 output_scale: 2.995\n",
      "Iter 250/500 - Loss: -1.135   noise: 0.000 output_scale: 3.006\n",
      "Iter 251/500 - Loss: -1.135   noise: 0.000 output_scale: 3.016\n",
      "Iter 252/500 - Loss: -1.135   noise: 0.000 output_scale: 3.027\n",
      "Iter 253/500 - Loss: -1.136   noise: 0.000 output_scale: 3.039\n",
      "Iter 254/500 - Loss: -1.136   noise: 0.000 output_scale: 3.051\n",
      "Iter 255/500 - Loss: -1.135   noise: 0.000 output_scale: 3.064\n",
      "Iter 256/500 - Loss: -1.136   noise: 0.000 output_scale: 3.077\n",
      "Iter 257/500 - Loss: -1.136   noise: 0.000 output_scale: 3.089\n",
      "Iter 258/500 - Loss: -1.137   noise: 0.000 output_scale: 3.100\n",
      "Iter 259/500 - Loss: -1.136   noise: 0.000 output_scale: 3.111\n",
      "Iter 260/500 - Loss: -1.137   noise: 0.000 output_scale: 3.121\n",
      "Iter 261/500 - Loss: -1.137   noise: 0.000 output_scale: 3.131\n",
      "Iter 262/500 - Loss: -1.137   noise: 0.000 output_scale: 3.143\n",
      "Iter 263/500 - Loss: -1.137   noise: 0.000 output_scale: 3.155\n",
      "Iter 264/500 - Loss: -1.137   noise: 0.000 output_scale: 3.166\n",
      "Iter 265/500 - Loss: -1.138   noise: 0.000 output_scale: 3.177\n",
      "Iter 266/500 - Loss: -1.137   noise: 0.000 output_scale: 3.188\n",
      "Iter 267/500 - Loss: -1.138   noise: 0.000 output_scale: 3.200\n",
      "Iter 268/500 - Loss: -1.138   noise: 0.000 output_scale: 3.212\n",
      "Iter 269/500 - Loss: -1.139   noise: 0.000 output_scale: 3.222\n",
      "Iter 270/500 - Loss: -1.138   noise: 0.000 output_scale: 3.232\n",
      "Iter 271/500 - Loss: -1.138   noise: 0.000 output_scale: 3.242\n",
      "Iter 272/500 - Loss: -1.139   noise: 0.000 output_scale: 3.253\n",
      "Iter 273/500 - Loss: -1.139   noise: 0.000 output_scale: 3.263\n",
      "Iter 274/500 - Loss: -1.139   noise: 0.000 output_scale: 3.274\n",
      "Iter 275/500 - Loss: -1.139   noise: 0.000 output_scale: 3.286\n",
      "Iter 276/500 - Loss: -1.139   noise: 0.000 output_scale: 3.298\n",
      "Iter 277/500 - Loss: -1.139   noise: 0.000 output_scale: 3.312\n",
      "Iter 278/500 - Loss: -1.140   noise: 0.000 output_scale: 3.326\n",
      "Iter 279/500 - Loss: -1.140   noise: 0.000 output_scale: 3.338\n",
      "Iter 280/500 - Loss: -1.140   noise: 0.000 output_scale: 3.349\n",
      "Iter 281/500 - Loss: -1.140   noise: 0.000 output_scale: 3.359\n",
      "Iter 282/500 - Loss: -1.141   noise: 0.000 output_scale: 3.369\n",
      "Iter 283/500 - Loss: -1.140   noise: 0.000 output_scale: 3.379\n",
      "Iter 284/500 - Loss: -1.141   noise: 0.000 output_scale: 3.389\n",
      "Iter 285/500 - Loss: -1.141   noise: 0.000 output_scale: 3.399\n",
      "Iter 286/500 - Loss: -1.141   noise: 0.000 output_scale: 3.410\n",
      "Iter 287/500 - Loss: -1.141   noise: 0.000 output_scale: 3.422\n",
      "Iter 288/500 - Loss: -1.142   noise: 0.000 output_scale: 3.435\n",
      "Iter 289/500 - Loss: -1.142   noise: 0.000 output_scale: 3.450\n",
      "Iter 290/500 - Loss: -1.142   noise: 0.000 output_scale: 3.465\n",
      "Iter 291/500 - Loss: -1.142   noise: 0.000 output_scale: 3.479\n",
      "Iter 292/500 - Loss: -1.142   noise: 0.000 output_scale: 3.492\n",
      "Iter 293/500 - Loss: -1.142   noise: 0.000 output_scale: 3.502\n",
      "Iter 294/500 - Loss: -1.142   noise: 0.000 output_scale: 3.513\n",
      "Iter 295/500 - Loss: -1.142   noise: 0.000 output_scale: 3.523\n",
      "Iter 296/500 - Loss: -1.142   noise: 0.000 output_scale: 3.533\n",
      "Iter 297/500 - Loss: -1.143   noise: 0.000 output_scale: 3.544\n",
      "Iter 298/500 - Loss: -1.143   noise: 0.000 output_scale: 3.554\n",
      "Iter 299/500 - Loss: -1.142   noise: 0.000 output_scale: 3.565\n",
      "Iter 300/500 - Loss: -1.143   noise: 0.000 output_scale: 3.576\n",
      "Iter 301/500 - Loss: -1.143   noise: 0.000 output_scale: 3.587\n",
      "Iter 302/500 - Loss: -1.144   noise: 0.000 output_scale: 3.598\n",
      "Iter 303/500 - Loss: -1.144   noise: 0.000 output_scale: 3.608\n",
      "Iter 304/500 - Loss: -1.143   noise: 0.000 output_scale: 3.616\n",
      "Iter 305/500 - Loss: -1.144   noise: 0.000 output_scale: 3.626\n",
      "Iter 306/500 - Loss: -1.145   noise: 0.000 output_scale: 3.635\n",
      "Iter 307/500 - Loss: -1.144   noise: 0.000 output_scale: 3.644\n",
      "Iter 308/500 - Loss: -1.144   noise: 0.000 output_scale: 3.654\n",
      "Iter 309/500 - Loss: -1.144   noise: 0.000 output_scale: 3.665\n",
      "Iter 310/500 - Loss: -1.145   noise: 0.000 output_scale: 3.676\n",
      "Iter 311/500 - Loss: -1.145   noise: 0.000 output_scale: 3.687\n",
      "Iter 312/500 - Loss: -1.145   noise: 0.000 output_scale: 3.699\n",
      "Iter 313/500 - Loss: -1.145   noise: 0.000 output_scale: 3.711\n",
      "Iter 314/500 - Loss: -1.145   noise: 0.000 output_scale: 3.724\n",
      "Iter 315/500 - Loss: -1.145   noise: 0.000 output_scale: 3.737\n",
      "Iter 316/500 - Loss: -1.145   noise: 0.000 output_scale: 3.750\n",
      "Iter 317/500 - Loss: -1.146   noise: 0.000 output_scale: 3.762\n",
      "Iter 318/500 - Loss: -1.146   noise: 0.000 output_scale: 3.774\n",
      "Iter 319/500 - Loss: -1.146   noise: 0.000 output_scale: 3.786\n",
      "Iter 320/500 - Loss: -1.146   noise: 0.000 output_scale: 3.797\n",
      "Iter 321/500 - Loss: -1.146   noise: 0.000 output_scale: 3.808\n",
      "Iter 322/500 - Loss: -1.146   noise: 0.000 output_scale: 3.820\n",
      "Iter 323/500 - Loss: -1.146   noise: 0.000 output_scale: 3.834\n",
      "Iter 324/500 - Loss: -1.147   noise: 0.000 output_scale: 3.847\n",
      "Iter 325/500 - Loss: -1.146   noise: 0.000 output_scale: 3.860\n",
      "Iter 326/500 - Loss: -1.147   noise: 0.000 output_scale: 3.875\n",
      "Iter 327/500 - Loss: -1.147   noise: 0.000 output_scale: 3.889\n",
      "Iter 328/500 - Loss: -1.147   noise: 0.000 output_scale: 3.902\n",
      "Iter 329/500 - Loss: -1.147   noise: 0.000 output_scale: 3.914\n",
      "Iter 330/500 - Loss: -1.147   noise: 0.000 output_scale: 3.925\n",
      "Iter 331/500 - Loss: -1.147   noise: 0.000 output_scale: 3.935\n",
      "Iter 332/500 - Loss: -1.148   noise: 0.000 output_scale: 3.944\n",
      "Iter 333/500 - Loss: -1.147   noise: 0.000 output_scale: 3.954\n",
      "Iter 334/500 - Loss: -1.148   noise: 0.000 output_scale: 3.966\n",
      "Iter 335/500 - Loss: -1.148   noise: 0.000 output_scale: 3.978\n",
      "Iter 336/500 - Loss: -1.148   noise: 0.000 output_scale: 3.992\n",
      "Iter 337/500 - Loss: -1.148   noise: 0.000 output_scale: 4.006\n",
      "Iter 338/500 - Loss: -1.148   noise: 0.000 output_scale: 4.020\n",
      "Iter 339/500 - Loss: -1.148   noise: 0.000 output_scale: 4.033\n",
      "Iter 340/500 - Loss: -1.148   noise: 0.000 output_scale: 4.046\n",
      "Iter 341/500 - Loss: -1.148   noise: 0.000 output_scale: 4.058\n",
      "Iter 342/500 - Loss: -1.148   noise: 0.000 output_scale: 4.070\n",
      "Iter 343/500 - Loss: -1.149   noise: 0.000 output_scale: 4.081\n",
      "Iter 344/500 - Loss: -1.148   noise: 0.000 output_scale: 4.089\n",
      "Iter 345/500 - Loss: -1.148   noise: 0.000 output_scale: 4.098\n",
      "Iter 346/500 - Loss: -1.149   noise: 0.000 output_scale: 4.107\n",
      "Iter 347/500 - Loss: -1.149   noise: 0.000 output_scale: 4.116\n",
      "Iter 348/500 - Loss: -1.149   noise: 0.000 output_scale: 4.126\n",
      "Iter 349/500 - Loss: -1.150   noise: 0.000 output_scale: 4.137\n",
      "Iter 350/500 - Loss: -1.149   noise: 0.000 output_scale: 4.148\n",
      "Iter 351/500 - Loss: -1.149   noise: 0.000 output_scale: 4.160\n",
      "Iter 352/500 - Loss: -1.150   noise: 0.000 output_scale: 4.172\n",
      "Iter 353/500 - Loss: -1.150   noise: 0.000 output_scale: 4.183\n",
      "Iter 354/500 - Loss: -1.150   noise: 0.000 output_scale: 4.194\n",
      "Iter 355/500 - Loss: -1.150   noise: 0.000 output_scale: 4.204\n",
      "Iter 356/500 - Loss: -1.150   noise: 0.000 output_scale: 4.213\n",
      "Iter 357/500 - Loss: -1.150   noise: 0.000 output_scale: 4.223\n",
      "Iter 358/500 - Loss: -1.150   noise: 0.000 output_scale: 4.232\n",
      "Iter 359/500 - Loss: -1.150   noise: 0.000 output_scale: 4.243\n",
      "Iter 360/500 - Loss: -1.150   noise: 0.000 output_scale: 4.254\n",
      "Iter 361/500 - Loss: -1.151   noise: 0.000 output_scale: 4.265\n",
      "Iter 362/500 - Loss: -1.151   noise: 0.000 output_scale: 4.277\n",
      "Iter 363/500 - Loss: -1.151   noise: 0.000 output_scale: 4.289\n",
      "Iter 364/500 - Loss: -1.152   noise: 0.000 output_scale: 4.301\n",
      "Iter 365/500 - Loss: -1.151   noise: 0.000 output_scale: 4.312\n",
      "Iter 366/500 - Loss: -1.151   noise: 0.000 output_scale: 4.322\n",
      "Iter 367/500 - Loss: -1.151   noise: 0.000 output_scale: 4.332\n",
      "Iter 368/500 - Loss: -1.152   noise: 0.000 output_scale: 4.343\n",
      "Iter 369/500 - Loss: -1.152   noise: 0.000 output_scale: 4.354\n",
      "Iter 370/500 - Loss: -1.152   noise: 0.000 output_scale: 4.365\n",
      "Iter 371/500 - Loss: -1.152   noise: 0.000 output_scale: 4.376\n",
      "Iter 372/500 - Loss: -1.152   noise: 0.000 output_scale: 4.387\n",
      "Iter 373/500 - Loss: -1.152   noise: 0.000 output_scale: 4.397\n",
      "Iter 374/500 - Loss: -1.152   noise: 0.000 output_scale: 4.408\n",
      "Iter 375/500 - Loss: -1.153   noise: 0.000 output_scale: 4.420\n",
      "Iter 376/500 - Loss: -1.152   noise: 0.000 output_scale: 4.430\n",
      "Iter 377/500 - Loss: -1.152   noise: 0.000 output_scale: 4.442\n",
      "Iter 378/500 - Loss: -1.152   noise: 0.000 output_scale: 4.455\n",
      "Iter 379/500 - Loss: -1.152   noise: 0.000 output_scale: 4.469\n",
      "Iter 380/500 - Loss: -1.154   noise: 0.000 output_scale: 4.484\n",
      "Iter 381/500 - Loss: -1.153   noise: 0.000 output_scale: 4.496\n",
      "Iter 382/500 - Loss: -1.153   noise: 0.000 output_scale: 4.507\n",
      "Iter 383/500 - Loss: -1.152   noise: 0.000 output_scale: 4.518\n",
      "Iter 384/500 - Loss: -1.153   noise: 0.000 output_scale: 4.531\n",
      "Iter 385/500 - Loss: -1.153   noise: 0.000 output_scale: 4.545\n",
      "Iter 386/500 - Loss: -1.153   noise: 0.000 output_scale: 4.557\n",
      "Iter 387/500 - Loss: -1.152   noise: 0.000 output_scale: 4.568\n",
      "Iter 388/500 - Loss: -1.153   noise: 0.000 output_scale: 4.582\n",
      "Iter 389/500 - Loss: -1.153   noise: 0.000 output_scale: 4.595\n",
      "Iter 390/500 - Loss: -1.153   noise: 0.000 output_scale: 4.608\n",
      "Iter 391/500 - Loss: -1.153   noise: 0.000 output_scale: 4.621\n",
      "Iter 392/500 - Loss: -1.153   noise: 0.000 output_scale: 4.634\n",
      "Iter 393/500 - Loss: -1.153   noise: 0.000 output_scale: 4.645\n",
      "Iter 394/500 - Loss: -1.153   noise: 0.000 output_scale: 4.657\n",
      "Iter 395/500 - Loss: -1.154   noise: 0.000 output_scale: 4.667\n",
      "Iter 396/500 - Loss: -1.154   noise: 0.000 output_scale: 4.678\n",
      "Iter 397/500 - Loss: -1.153   noise: 0.000 output_scale: 4.688\n",
      "Iter 398/500 - Loss: -1.154   noise: 0.000 output_scale: 4.700\n",
      "Iter 399/500 - Loss: -1.154   noise: 0.000 output_scale: 4.713\n",
      "Iter 400/500 - Loss: -1.154   noise: 0.000 output_scale: 4.723\n",
      "Iter 401/500 - Loss: -1.154   noise: 0.000 output_scale: 4.734\n",
      "Iter 402/500 - Loss: -1.155   noise: 0.000 output_scale: 4.744\n",
      "Iter 403/500 - Loss: -1.155   noise: 0.000 output_scale: 4.753\n",
      "Iter 404/500 - Loss: -1.155   noise: 0.000 output_scale: 4.763\n",
      "Iter 405/500 - Loss: -1.155   noise: 0.000 output_scale: 4.773\n",
      "Iter 406/500 - Loss: -1.154   noise: 0.000 output_scale: 4.783\n",
      "Iter 407/500 - Loss: -1.156   noise: 0.000 output_scale: 4.796\n",
      "Iter 408/500 - Loss: -1.154   noise: 0.000 output_scale: 4.808\n",
      "Iter 409/500 - Loss: -1.155   noise: 0.000 output_scale: 4.820\n",
      "Iter 410/500 - Loss: -1.155   noise: 0.000 output_scale: 4.832\n",
      "Iter 411/500 - Loss: -1.155   noise: 0.000 output_scale: 4.846\n",
      "Iter 412/500 - Loss: -1.155   noise: 0.000 output_scale: 4.858\n",
      "Iter 413/500 - Loss: -1.155   noise: 0.000 output_scale: 4.870\n",
      "Iter 414/500 - Loss: -1.155   noise: 0.000 output_scale: 4.883\n",
      "Iter 415/500 - Loss: -1.156   noise: 0.000 output_scale: 4.896\n",
      "Iter 416/500 - Loss: -1.154   noise: 0.000 output_scale: 4.907\n",
      "Iter 417/500 - Loss: -1.155   noise: 0.000 output_scale: 4.919\n",
      "Iter 418/500 - Loss: -1.155   noise: 0.000 output_scale: 4.931\n",
      "Iter 419/500 - Loss: -1.155   noise: 0.000 output_scale: 4.942\n",
      "Iter 420/500 - Loss: -1.155   noise: 0.000 output_scale: 4.953\n",
      "Iter 421/500 - Loss: -1.155   noise: 0.000 output_scale: 4.965\n",
      "Iter 422/500 - Loss: -1.156   noise: 0.000 output_scale: 4.976\n",
      "Iter 423/500 - Loss: -1.156   noise: 0.000 output_scale: 4.986\n",
      "Iter 424/500 - Loss: -1.156   noise: 0.000 output_scale: 4.995\n",
      "Iter 425/500 - Loss: -1.157   noise: 0.000 output_scale: 5.003\n",
      "Iter 426/500 - Loss: -1.156   noise: 0.000 output_scale: 5.011\n",
      "Iter 427/500 - Loss: -1.156   noise: 0.000 output_scale: 5.020\n",
      "Iter 428/500 - Loss: -1.157   noise: 0.000 output_scale: 5.031\n",
      "Iter 429/500 - Loss: -1.156   noise: 0.000 output_scale: 5.042\n",
      "Iter 430/500 - Loss: -1.156   noise: 0.000 output_scale: 5.055\n",
      "Iter 431/500 - Loss: -1.155   noise: 0.000 output_scale: 5.070\n",
      "Iter 432/500 - Loss: -1.156   noise: 0.000 output_scale: 5.086\n",
      "Iter 433/500 - Loss: -1.157   noise: 0.000 output_scale: 5.103\n",
      "Iter 434/500 - Loss: -1.157   noise: 0.000 output_scale: 5.119\n",
      "Iter 435/500 - Loss: -1.157   noise: 0.000 output_scale: 5.134\n",
      "Iter 436/500 - Loss: -1.156   noise: 0.000 output_scale: 5.145\n",
      "Iter 437/500 - Loss: -1.157   noise: 0.000 output_scale: 5.155\n",
      "Iter 438/500 - Loss: -1.157   noise: 0.000 output_scale: 5.162\n",
      "Iter 439/500 - Loss: -1.157   noise: 0.000 output_scale: 5.170\n",
      "Iter 440/500 - Loss: -1.158   noise: 0.000 output_scale: 5.179\n",
      "Iter 441/500 - Loss: -1.157   noise: 0.000 output_scale: 5.189\n",
      "Iter 442/500 - Loss: -1.157   noise: 0.000 output_scale: 5.201\n",
      "Iter 443/500 - Loss: -1.157   noise: 0.000 output_scale: 5.213\n",
      "Iter 444/500 - Loss: -1.157   noise: 0.000 output_scale: 5.228\n",
      "Iter 445/500 - Loss: -1.157   noise: 0.000 output_scale: 5.243\n",
      "Iter 446/500 - Loss: -1.160   noise: 0.000 output_scale: 5.258\n",
      "Iter 447/500 - Loss: -1.158   noise: 0.000 output_scale: 5.269\n",
      "Iter 448/500 - Loss: -1.159   noise: 0.000 output_scale: 5.279\n",
      "Iter 449/500 - Loss: -1.158   noise: 0.000 output_scale: 5.286\n",
      "Iter 450/500 - Loss: -1.158   noise: 0.000 output_scale: 5.294\n",
      "Iter 451/500 - Loss: -1.157   noise: 0.000 output_scale: 5.303\n",
      "Iter 452/500 - Loss: -1.157   noise: 0.000 output_scale: 5.314\n",
      "Iter 453/500 - Loss: -1.159   noise: 0.000 output_scale: 5.328\n",
      "Iter 454/500 - Loss: -1.158   noise: 0.000 output_scale: 5.340\n",
      "Iter 455/500 - Loss: -1.157   noise: 0.000 output_scale: 5.351\n",
      "Iter 456/500 - Loss: -1.157   noise: 0.000 output_scale: 5.365\n",
      "Iter 457/500 - Loss: -1.158   noise: 0.000 output_scale: 5.380\n",
      "Iter 458/500 - Loss: -1.157   noise: 0.000 output_scale: 5.393\n",
      "Iter 459/500 - Loss: -1.158   noise: 0.000 output_scale: 5.405\n",
      "Iter 460/500 - Loss: -1.158   noise: 0.000 output_scale: 5.416\n",
      "Iter 461/500 - Loss: -1.158   noise: 0.000 output_scale: 5.426\n",
      "Iter 462/500 - Loss: -1.157   noise: 0.000 output_scale: 5.435\n",
      "Iter 463/500 - Loss: -1.159   noise: 0.000 output_scale: 5.444\n",
      "Iter 464/500 - Loss: -1.158   noise: 0.000 output_scale: 5.453\n",
      "Iter 465/500 - Loss: -1.158   noise: 0.000 output_scale: 5.462\n",
      "Iter 466/500 - Loss: -1.158   noise: 0.000 output_scale: 5.471\n",
      "Iter 467/500 - Loss: -1.160   noise: 0.000 output_scale: 5.481\n",
      "Iter 468/500 - Loss: -1.159   noise: 0.000 output_scale: 5.490\n",
      "Iter 469/500 - Loss: -1.159   noise: 0.000 output_scale: 5.501\n",
      "Iter 470/500 - Loss: -1.158   noise: 0.000 output_scale: 5.513\n",
      "Iter 471/500 - Loss: -1.159   noise: 0.000 output_scale: 5.527\n",
      "Iter 472/500 - Loss: -1.159   noise: 0.000 output_scale: 5.539\n",
      "Iter 473/500 - Loss: -1.160   noise: 0.000 output_scale: 5.551\n",
      "Iter 474/500 - Loss: -1.159   noise: 0.000 output_scale: 5.562\n",
      "Iter 475/500 - Loss: -1.159   noise: 0.000 output_scale: 5.572\n",
      "Iter 476/500 - Loss: -1.160   noise: 0.000 output_scale: 5.581\n",
      "Iter 477/500 - Loss: -1.160   noise: 0.000 output_scale: 5.589\n",
      "Iter 478/500 - Loss: -1.159   noise: 0.000 output_scale: 5.596\n",
      "Iter 479/500 - Loss: -1.159   noise: 0.000 output_scale: 5.605\n",
      "Iter 480/500 - Loss: -1.160   noise: 0.000 output_scale: 5.615\n",
      "Iter 481/500 - Loss: -1.160   noise: 0.000 output_scale: 5.626\n",
      "Iter 482/500 - Loss: -1.159   noise: 0.000 output_scale: 5.637\n",
      "Iter 483/500 - Loss: -1.159   noise: 0.000 output_scale: 5.648\n",
      "Iter 484/500 - Loss: -1.160   noise: 0.000 output_scale: 5.661\n",
      "Iter 485/500 - Loss: -1.161   noise: 0.000 output_scale: 5.672\n",
      "Iter 486/500 - Loss: -1.161   noise: 0.000 output_scale: 5.682\n",
      "Iter 487/500 - Loss: -1.160   noise: 0.000 output_scale: 5.691\n",
      "Iter 488/500 - Loss: -1.160   noise: 0.000 output_scale: 5.702\n",
      "Iter 489/500 - Loss: -1.160   noise: 0.000 output_scale: 5.713\n",
      "Iter 490/500 - Loss: -1.161   noise: 0.000 output_scale: 5.725\n",
      "Iter 491/500 - Loss: -1.161   noise: 0.000 output_scale: 5.737\n",
      "Iter 492/500 - Loss: -1.160   noise: 0.000 output_scale: 5.749\n",
      "Iter 493/500 - Loss: -1.161   noise: 0.000 output_scale: 5.761\n",
      "Iter 494/500 - Loss: -1.160   noise: 0.000 output_scale: 5.773\n",
      "Iter 495/500 - Loss: -1.161   noise: 0.000 output_scale: 5.786\n",
      "Iter 496/500 - Loss: -1.161   noise: 0.000 output_scale: 5.801\n",
      "Iter 497/500 - Loss: -1.161   noise: 0.000 output_scale: 5.814\n",
      "Iter 498/500 - Loss: -1.161   noise: 0.000 output_scale: 5.827\n",
      "Iter 499/500 - Loss: -1.161   noise: 0.000 output_scale: 5.841\n",
      "Iter 500/500 - Loss: -1.160   noise: 0.000 output_scale: 5.854\n",
      "MultivariateNormal(loc: torch.Size([30]))\n",
      "0.37587124\n",
      "tensor(0.2043)\n"
     ]
    }
   ],
   "source": [
    "import jax.random as jr\n",
    "import uci_datasets\n",
    "import gpytorch\n",
    "\n",
    "from data import get_dataset\n",
    "\n",
    "train_ds, test_ds = get_dataset('yacht', normalise=True)\n",
    "\n",
    "print(train_ds.x.shape)\n",
    "\n",
    "\n",
    "# model.likelihood.noise_covar._set_noise(0.0007456933963112533)\n",
    "# model.covar_module._set_outputscale(0.07279852032661438)\n",
    "# model.covar_module.base_kernel._set_lengthscale(torch.from_numpy(np.asarray([0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "#   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "#   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "#   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "#   5.5808063,  5.1676707])))\"\"\n",
    "\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        kernel = gpt.kernels.MaternKernel(nu=1.5, ard_num_dims=6)\n",
    "        # lengthscales = torch.from_numpy(np.asarray([0.17658784985542297, 0.19303946197032928, 0.30149734020233154, 0.3629351556301117, 0.2601526975631714, 1.06342351436615, 1.1373639106750488, 3.021310567855835, 3.348904848098755, 1.3357858657836914, 1.2393946647644043, 1.1090068817138672, 2.8051507472991943, 2.5480997562408447, 2.2725119590759277, 0.9565914869308472, 2.9568326473236084, 3.3208203315734863, 3.3087961673736572, 2.968641996383667, 2.4997735023498535, 3.0178418159484863, 3.307901620864868, 1.6029528379440308, 3.3901262283325195, 3.302780866622925]))\n",
    "        \n",
    "#         lengthscales = torch.from_numpy(np.asarray([0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "#   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "#   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "#   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "#   5.5808063,  5.1676707]))\n",
    "        \n",
    "        # ('os', '0.09691217'), ('noise', '0.00168458'), ('ls', '1.88330865')\n",
    "        # kernel.lengthscale = 1.88330865\n",
    "        # kernel.lengthscale = lengthscales\n",
    "        # print(f'lengtscales: {kernel.lengthscale}')\n",
    "        \n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(kernel)\n",
    "        # self.covar_module.outputscale(1.)\n",
    "        # print(f'output_scale : ', self.covar_module.outputscale)\n",
    "        # self.covar_module.outputscale = 0.07279852032661438\n",
    "        # self.covar_module.outputscale = 0.10929246991872787\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "x = torch.from_numpy(np.array(train_ds.x)).float()\n",
    "y = torch.from_numpy(np.array(train_ds.y)).float()\n",
    "\n",
    "test_x = torch.from_numpy(np.array(test_ds.x)).float()\n",
    "test_y = torch.from_numpy(np.array(test_ds.y)).float()\n",
    "\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# log(1 + e(x)) = lg(e^10 - 1)\n",
    "# likelihood.noise_covar.noise = 0.0016845794161781669\n",
    "# likelihood.noise_covar.noise =0.00807290431112051\n",
    "# likelihood.noise_covar.noise = 0.0007456933963112533\n",
    "print('noise : ', likelihood.noise_covar.noise)\n",
    "\n",
    "model = ExactGPModel(x, y, likelihood)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Overwrite quantities\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    latent_pred = model(test_x)\n",
    "    \n",
    "print(latent_pred)\n",
    "\n",
    "test_rmse = torch.sqrt(torch.mean(torch.pow(latent_pred.mean - test_y, 2)))\n",
    "\n",
    "from eval_utils import RMSE\n",
    "\n",
    "test_y_jax = jnp.array(test_y.numpy())\n",
    "mean_y_jax = jnp.array(latent_pred.mean.numpy())\n",
    "print(RMSE(test_y_jax, mean_y_jax, train_ds.mu_y, train_ds.sigma_y))\n",
    "\n",
    "print(test_rmse)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 500\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   noise: %.3f output_scale: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        # model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item(),    \\\n",
    "        model.covar_module.outputscale.item()\n",
    "    ))\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    latent_pred = model(test_x)\n",
    "    \n",
    "print(latent_pred)\n",
    "\n",
    "\n",
    "test_rmse = torch.sqrt(torch.mean(torch.pow(latent_pred.mean - test_y, 2)))\n",
    "\n",
    "from eval_utils import RMSE\n",
    "\n",
    "test_y_jax = jnp.array(test_y.numpy())\n",
    "mean_y_jax = jnp.array(latent_pred.mean.numpy())\n",
    "print(RMSE(test_y_jax, mean_y_jax, train_ds.mu_y, train_ds.sigma_y))\n",
    "\n",
    "print(test_rmse)\n",
    "# # kernel_gpt = gpt.kernels.MaternKernel(nu=1.5)\n",
    "# kernel_gpt = gpt.kernels.ScaleKernel(gpt.kernels.MaternKernel(nu=1.5))\n",
    "\n",
    "\n",
    "\n",
    "# # data = jr.normal(key=jr.PRNGKey(0), shape=(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15.1872,  9.7537, 19.5300, 13.5691, 16.2901,  5.7411]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "0.01227042308395588\n",
      "2.4222777985351653\n"
     ]
    }
   ],
   "source": [
    "print(model.covar_module.base_kernel.lengthscale)\n",
    "print(np.sqrt(model.likelihood.noise.item()))\n",
    "print(np.sqrt(model.covar_module.outputscale.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40078604 0.47861066 0.99160534 1.8033762  1.3364722  3.6816106\n",
      "  3.6552188  6.4623747  6.9620767  4.8550777  2.6934228  2.2448704\n",
      "  5.32376    5.58768    6.0296025  3.2405155  6.1585517  6.8495193\n",
      "  5.000094   5.8355484  5.2284794  6.537194   6.9643164  5.1460247\n",
      "  5.5808063  5.1676707 ]]\n",
      "0.0007456933963112533\n",
      "0.0007456933963112533\n",
      "0.07279852032661438\n",
      "[[0.40078604 0.47861066 0.99160534 1.8033762  1.3364722  3.6816106\n",
      "  3.6552188  6.4623747  6.9620767  4.8550777  2.6934228  2.2448704\n",
      "  5.32376    5.58768    6.0296025  3.2405155  6.1585517  6.8495193\n",
      "  5.000094   5.8355484  5.2284794  6.537194   6.9643164  5.1460247\n",
      "  5.5808063  5.1676707 ]]\n",
      "0.0007456933963112533\n",
      "0.0007456933963112533\n",
      "0.07279852032661438\n",
      "MultivariateNormal(loc: torch.Size([1500]))\n",
      "33.904427\n",
      "tensor(0.8120)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "print(model.covar_module.base_kernel.lengthscale.detach().numpy())\n",
    "print(model.likelihood.noise.item())\n",
    "print(likelihood.noise.item())\n",
    "print(model.covar_module.outputscale.item())\n",
    "\n",
    "\n",
    "print(model.covar_module.base_kernel.lengthscale.detach().numpy())\n",
    "print(model.likelihood.noise.item())\n",
    "print(likelihood.noise.item())\n",
    "print(model.covar_module.outputscale.item())\n",
    "\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    latent_pred = model(test_x)\n",
    "    \n",
    "print(latent_pred)\n",
    "\n",
    "\n",
    "test_rmse = torch.sqrt(torch.mean(torch.pow(latent_pred.mean - test_y, 2)))\n",
    "\n",
    "from eval_utils import RMSE\n",
    "\n",
    "test_y_jax = jnp.array(test_y.numpy())\n",
    "mean_y_jax = jnp.array(latent_pred.mean.numpy())\n",
    "print(RMSE(test_y_jax, mean_y_jax, train_ds.mu_y, train_ds.sigma_y))\n",
    "\n",
    "print(test_rmse)\n",
    "\n",
    "# insert commas into followign list - [0.40078604 0.47861066 0.99160534 1.8033762  1.3364722  3.6816106\n",
    "#   3.6552188  6.462375   6.962077   4.8550777  2.6934228  2.2448704\n",
    "#   5.32376    5.58768    6.0296025  3.2405155  6.1585517  6.8495193\n",
    "#   5.000094   5.8355484  5.228479   6.537194   6.9643164  5.146025\n",
    "#   5.5808063  5.1676707 ]\n",
    "  \n",
    "# model.covar_module.base_kernel.lengthscale = [0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "#   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "#   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "#   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "#   5.5808063,  5.1676707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [[0.17658784985542297, 0.19303946197032928, 0.30149734020233154, 0.3629351556301117, 0.2601526975631714, 1.06342351436615, 1.1373639106750488, 3.021310567855835, 3.348904848098755, 1.3357858657836914, 1.2393946647644043, 1.1090068817138672, 2.8051507472991943, 2.5480997562408447, 2.2725119590759277, 0.9565914869308472, 2.9568326473236084, 3.3208203315734863, 3.3087961673736572, 2.968641996383667, 2.4997735023498535, 3.0178418159484863, 3.307901620864868, 1.6029528379440308, 3.3901262283325195, 3.302780866622925]]\n",
    "\n",
    "l2 = [[0.18632957339286804, 0.18670417368412018, 0.3110752999782562, 0.38153818249702454, 0.2578975260257721, 1.0106427669525146, 1.149392008781433, 3.015958547592163, 3.4424891471862793, 1.3288651704788208, 1.2516462802886963, 0.9662008285522461, 2.8585398197174072, 2.4922971725463867, 2.5090160369873047, 0.8172422051429749, 2.799964666366577, 3.24336838722229, 3.2503981590270996, 3.061379909515381, 2.3566246032714844, 2.9445431232452393, 3.2977046966552734, 1.5283869504928589, 3.285978317260742, 3.14375638961792]]\n",
    "\n",
    "l3 = [[0.18384207785129547, 0.18583382666110992, 0.2833012640476227, 0.3608447313308716, 0.24685616791248322, 0.9405211210250854, 1.130507230758667, 2.9164040088653564, 3.31789493560791, 1.364676594734192, 1.2581337690353394, 1.1084792613983154, 2.7693064212799072, 2.4154539108276367, 2.3878650665283203, 0.786465048789978, 2.850242853164673, 3.3356235027313232, 3.2113757133483887, 3.167024850845337, 2.1103827953338623, 3.0827345848083496, 3.291494846343994, 1.6791802644729614, 3.3651740550994873, 3.087095022201538]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
