{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scalable_gps\n",
    "from scalable_gps.kernels import Matern32Kernel\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import gpytorch as gpt\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpflux\n",
    "# filepath = '/home/shreyaspadhy_gmail_com/scalable-gaussian-processes/scalable_gps/results/exact_gp_results/dataset_pol.evaltol_0.001.kernel_matern.loverank_200.lr_0.1.model_exact.numiter_100.seed_0.traintol_1.0.pkl'\n",
    "\n",
    "\n",
    "# with open(filepath, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pol dataset, N=15000, d=26\n",
      "(13500, 26)\n",
      "noise :  tensor([0.0081], grad_fn=<AddBackward0>)\n",
      "output_scale :  tensor(0.6931, grad_fn=<SoftplusBackward0>)\n",
      "ExactGPModel(\n",
      "  (likelihood): GaussianLikelihood(\n",
      "    (noise_covar): HomoskedasticNoise(\n",
      "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
      "    )\n",
      "  )\n",
      "  (mean_module): ConstantMean()\n",
      "  (covar_module): ScaleKernel(\n",
      "    (base_kernel): MaternKernel(\n",
      "      (raw_lengthscale_constraint): Positive()\n",
      "    )\n",
      "    (raw_outputscale_constraint): Positive()\n",
      "  )\n",
      ")\n",
      "MultivariateNormal(loc: torch.Size([1500]))\n",
      "39.927296\n",
      "tensor(39.9273)\n"
     ]
    }
   ],
   "source": [
    "import jax.random as jr\n",
    "import uci_datasets\n",
    "import gpytorch\n",
    "\n",
    "from data import get_dataset\n",
    "\n",
    "train_ds, test_ds = get_dataset('pol', normalise=False)\n",
    "\n",
    "print(train_ds.x.shape)\n",
    "\n",
    "\n",
    "# model.likelihood.noise_covar._set_noise(0.0007456933963112533)\n",
    "# model.covar_module._set_outputscale(0.07279852032661438)\n",
    "# model.covar_module.base_kernel._set_lengthscale(torch.from_numpy(np.asarray([0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "#   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "#   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "#   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "#   5.5808063,  5.1676707])))\n",
    "\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        kernel = gpt.kernels.MaternKernel(nu=1.5, ard_num_dims=26)\n",
    "        lengthscales = torch.from_numpy(np.asarray([0.17658784985542297, 0.19303946197032928, 0.30149734020233154, 0.3629351556301117, 0.2601526975631714, 1.06342351436615, 1.1373639106750488, 3.021310567855835, 3.348904848098755, 1.3357858657836914, 1.2393946647644043, 1.1090068817138672, 2.8051507472991943, 2.5480997562408447, 2.2725119590759277, 0.9565914869308472, 2.9568326473236084, 3.3208203315734863, 3.3087961673736572, 2.968641996383667, 2.4997735023498535, 3.0178418159484863, 3.307901620864868, 1.6029528379440308, 3.3901262283325195, 3.302780866622925]))\n",
    "        \n",
    "#         lengthscales = torch.from_numpy(np.asarray([0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "#   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "#   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "#   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "#   5.5808063,  5.1676707]))\n",
    "        \n",
    "        # ('os', '0.09691217'), ('noise', '0.00168458'), ('ls', '1.88330865')\n",
    "        # kernel.lengthscale = 1.88330865\n",
    "        kernel.lengthscale = lengthscales\n",
    "        # print(f'lengtscales: {kernel.lengthscale}')\n",
    "        \n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(kernel)\n",
    "        # self.covar_module.outputscale(1.)\n",
    "        print(f'output_scale : ', self.covar_module.outputscale)\n",
    "        # self.covar_module.outputscale = 0.07279852032661438\n",
    "        self.covar_module.outputscale = 0.10929246991872787\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "x = torch.from_numpy(np.array(train_ds.x)).float()\n",
    "y = torch.from_numpy(np.array(train_ds.y)).float()\n",
    "\n",
    "test_x = torch.from_numpy(np.array(test_ds.x)).float()\n",
    "test_y = torch.from_numpy(np.array(test_ds.y)).float()\n",
    "\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# log(1 + e(x)) = lg(e^10 - 1)\n",
    "# likelihood.noise_covar.noise = 0.0016845794161781669\n",
    "likelihood.noise_covar.noise =0.00807290431112051\n",
    "# likelihood.noise_covar.noise = 0.0007456933963112533\n",
    "print('noise : ', likelihood.noise_covar.noise)\n",
    "\n",
    "model = ExactGPModel(x, y, likelihood)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Overwrite quantities\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    latent_pred = model(test_x)\n",
    "    \n",
    "print(latent_pred)\n",
    "\n",
    "\n",
    "test_rmse = torch.sqrt(torch.mean(torch.pow(latent_pred.mean - test_y, 2)))\n",
    "\n",
    "from eval_utils import RMSE\n",
    "\n",
    "test_y_jax = jnp.array(test_y.numpy())\n",
    "mean_y_jax = jnp.array(latent_pred.mean.numpy())\n",
    "print(RMSE(test_y_jax, mean_y_jax, train_ds.mu_y, train_ds.sigma_y))\n",
    "\n",
    "print(test_rmse)\n",
    "\n",
    "# # Find optimal model hyperparameters\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # Use the adam optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# # \"Loss\" for GPs - the marginal log likelihood\n",
    "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# training_iter = 100\n",
    "# for i in range(training_iter):\n",
    "#     # Zero gradients from previous iteration\n",
    "#     optimizer.zero_grad()\n",
    "#     # Output from model\n",
    "#     output = model(x)\n",
    "#     # Calc loss and backprop gradients\n",
    "#     loss = -mll(output, y)\n",
    "#     loss.backward()\n",
    "#     print('Iter %d/%d - Loss: %.3f   noise: %.3f output_scale: %.3f' % (\n",
    "#         i + 1, training_iter, loss.item(),\n",
    "#         # model.covar_module.base_kernel.lengthscale.item(),\n",
    "#         model.likelihood.noise.item(),    \\\n",
    "#         model.covar_module.outputscale.item()\n",
    "#     ))\n",
    "#     optimizer.step()\n",
    "\n",
    "\n",
    "# # Get into evaluation (predictive posterior) mode\n",
    "# model.eval()\n",
    "# likelihood.eval()\n",
    "\n",
    "# # Test points are regularly spaced along [0,1]\n",
    "# # Make predictions by feeding model through likelihood\n",
    "# with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#     latent_pred = model(test_x)\n",
    "    \n",
    "# print(latent_pred)\n",
    "\n",
    "\n",
    "# test_rmse = torch.sqrt(torch.mean(torch.pow(latent_pred.mean - test_y, 2)))\n",
    "\n",
    "# from eval_utils import RMSE\n",
    "\n",
    "# test_y_jax = jnp.array(test_y.numpy())\n",
    "# mean_y_jax = jnp.array(latent_pred.mean.numpy())\n",
    "# print(RMSE(test_y_jax, mean_y_jax, train_ds.mu_y, train_ds.sigma_y))\n",
    "\n",
    "# print(test_rmse)\n",
    "# # # kernel_gpt = gpt.kernels.MaternKernel(nu=1.5)\n",
    "# # kernel_gpt = gpt.kernels.ScaleKernel(gpt.kernels.MaternKernel(nu=1.5))\n",
    "\n",
    "\n",
    "\n",
    "# # # data = jr.normal(key=jr.PRNGKey(0), shape=(10, 1))\n",
    "\n",
    "\n",
    "\n",
    "# data_torch = torch.from_numpy(np.array(data)).float()\n",
    "# data_jax = jnp.array(data)\n",
    "\n",
    "# covar_gpt = kernel_gpt(data_torch, data_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40078604 0.47861066 0.99160534 1.8033762  1.3364722  3.6816106\n",
      "  3.6552188  6.4623747  6.9620767  4.8550777  2.6934228  2.2448704\n",
      "  5.32376    5.58768    6.0296025  3.2405155  6.1585517  6.8495193\n",
      "  5.000094   5.8355484  5.2284794  6.537194   6.9643164  5.1460247\n",
      "  5.5808063  5.1676707 ]]\n",
      "0.0007456933963112533\n",
      "0.0007456933963112533\n",
      "0.07279852032661438\n",
      "[[0.40078604 0.47861066 0.99160534 1.8033762  1.3364722  3.6816106\n",
      "  3.6552188  6.4623747  6.9620767  4.8550777  2.6934228  2.2448704\n",
      "  5.32376    5.58768    6.0296025  3.2405155  6.1585517  6.8495193\n",
      "  5.000094   5.8355484  5.2284794  6.537194   6.9643164  5.1460247\n",
      "  5.5808063  5.1676707 ]]\n",
      "0.0007456933963112533\n",
      "0.0007456933963112533\n",
      "0.07279852032661438\n",
      "MultivariateNormal(loc: torch.Size([1500]))\n",
      "33.904427\n",
      "tensor(0.8120)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "print(model.covar_module.base_kernel.lengthscale.detach().numpy())\n",
    "print(model.likelihood.noise.item())\n",
    "print(likelihood.noise.item())\n",
    "print(model.covar_module.outputscale.item())\n",
    "\n",
    "\n",
    "print(model.covar_module.base_kernel.lengthscale.detach().numpy())\n",
    "print(model.likelihood.noise.item())\n",
    "print(likelihood.noise.item())\n",
    "print(model.covar_module.outputscale.item())\n",
    "\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    latent_pred = model(test_x)\n",
    "    \n",
    "print(latent_pred)\n",
    "\n",
    "\n",
    "test_rmse = torch.sqrt(torch.mean(torch.pow(latent_pred.mean - test_y, 2)))\n",
    "\n",
    "from eval_utils import RMSE\n",
    "\n",
    "test_y_jax = jnp.array(test_y.numpy())\n",
    "mean_y_jax = jnp.array(latent_pred.mean.numpy())\n",
    "print(RMSE(test_y_jax, mean_y_jax, train_ds.mu_y, train_ds.sigma_y))\n",
    "\n",
    "print(test_rmse)\n",
    "\n",
    "# insert commas into followign list - [0.40078604 0.47861066 0.99160534 1.8033762  1.3364722  3.6816106\n",
    "#   3.6552188  6.462375   6.962077   4.8550777  2.6934228  2.2448704\n",
    "#   5.32376    5.58768    6.0296025  3.2405155  6.1585517  6.8495193\n",
    "#   5.000094   5.8355484  5.228479   6.537194   6.9643164  5.146025\n",
    "#   5.5808063  5.1676707 ]\n",
    "  \n",
    "# model.covar_module.base_kernel.lengthscale = [0.40078604, 0.47861066, 0.99160534, 1.8033762,  1.3364722,  3.6816106,\n",
    "#   3.6552188,  6.462375,   6.962077,   4.8550777,  2.6934228,  2.2448704,\n",
    "#   5.32376,    5.58768,    6.0296025,  3.2405155,  6.1585517,  6.8495193,\n",
    "#   5.000094,   5.8355484,  5.228479,   6.537194,   6.9643164,  5.146025,\n",
    "#   5.5808063,  5.1676707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [[0.17658784985542297, 0.19303946197032928, 0.30149734020233154, 0.3629351556301117, 0.2601526975631714, 1.06342351436615, 1.1373639106750488, 3.021310567855835, 3.348904848098755, 1.3357858657836914, 1.2393946647644043, 1.1090068817138672, 2.8051507472991943, 2.5480997562408447, 2.2725119590759277, 0.9565914869308472, 2.9568326473236084, 3.3208203315734863, 3.3087961673736572, 2.968641996383667, 2.4997735023498535, 3.0178418159484863, 3.307901620864868, 1.6029528379440308, 3.3901262283325195, 3.302780866622925]]\n",
    "\n",
    "l2 = [[0.18632957339286804, 0.18670417368412018, 0.3110752999782562, 0.38153818249702454, 0.2578975260257721, 1.0106427669525146, 1.149392008781433, 3.015958547592163, 3.4424891471862793, 1.3288651704788208, 1.2516462802886963, 0.9662008285522461, 2.8585398197174072, 2.4922971725463867, 2.5090160369873047, 0.8172422051429749, 2.799964666366577, 3.24336838722229, 3.2503981590270996, 3.061379909515381, 2.3566246032714844, 2.9445431232452393, 3.2977046966552734, 1.5283869504928589, 3.285978317260742, 3.14375638961792]]\n",
    "\n",
    "l3 = [[0.18384207785129547, 0.18583382666110992, 0.2833012640476227, 0.3608447313308716, 0.24685616791248322, 0.9405211210250854, 1.130507230758667, 2.9164040088653564, 3.31789493560791, 1.364676594734192, 1.2581337690353394, 1.1084792613983154, 2.7693064212799072, 2.4154539108276367, 2.3878650665283203, 0.786465048789978, 2.850242853164673, 3.3356235027313232, 3.2113757133483887, 3.167024850845337, 2.1103827953338623, 3.0827345848083496, 3.291494846343994, 1.6791802644729614, 3.3651740550994873, 3.087095022201538]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
