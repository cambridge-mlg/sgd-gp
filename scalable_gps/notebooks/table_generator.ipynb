{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for pol, sgd already exists\n",
      "rmse for pol, cg already exists\n",
      "rmse for pol, precondcg already exists\n",
      "rmse for elevators, sgd already exists\n",
      "rmse for elevators, cg already exists\n",
      "rmse for elevators, precondcg already exists\n",
      "rmse for bike, sgd already exists\n",
      "rmse for bike, cg already exists\n",
      "rmse for bike, precondcg already exists\n",
      "rmse for protein, sgd already exists\n",
      "rmse for protein, cg already exists\n",
      "rmse for protein, precondcg already exists\n",
      "rmse for keggdirected, sgd already exists\n",
      "rmse for keggdirected, cg already exists\n",
      "rmse for keggdirected, precondcg already exists\n",
      "rmse for 3droad, sgd already exists\n",
      "rmse for 3droad, cg already exists\n",
      "rmse for 3droad, precondcg already exists\n",
      "rmse for song, sgd already exists\n",
      "rmse for song, cg already exists\n",
      "rmse for song, precondcg already exists\n",
      "rmse for buzz, sgd already exists\n",
      "rmse for buzz, cg already exists\n",
      "rmse for buzz, precondcg already exists\n",
      "rmse for houseelectric, sgd already exists\n",
      "rmse for houseelectric, cg already exists\n",
      "rmse for houseelectric, precondcg already exists\n"
     ]
    }
   ],
   "source": [
    "from scalable_gps.wandb_utils import load_runs_from_regex\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_splits(dataset):\n",
    "    if dataset == '3droad':\n",
    "        return [0, 1, 2, 4]\n",
    "    elif dataset == 'houseelectric':\n",
    "        return [0, 1, 2]\n",
    "    else:\n",
    "        return [0, 1, 2, 3, 4]\n",
    "\n",
    "datasets = ['pol',\n",
    "            'elevators',\n",
    "            'bike',\n",
    "            # 'kin40k',\n",
    "            'protein',\n",
    "            'keggdirected',\n",
    "            '3droad',\n",
    "            'song',\n",
    "            'buzz',\n",
    "            'houseelectric']\n",
    "\n",
    "models = ['sgd', 'cg', 'precondcg']#, 'vi']\n",
    "\n",
    "config_keys = ['model_name', 'dataset_config.split', 'override_noise_scale']\n",
    "metric_keys = ['wall_clock_time', 'normalised_test_rmse']\n",
    "\n",
    "rmse_dict_path = \"./table_rmse.npy\"\n",
    "\n",
    "if os.path.isfile(rmse_dict_path):\n",
    "    rmse_dict = np.load(rmse_dict_path, allow_pickle=True).item()\n",
    "else:\n",
    "    rmse_dict = dict()\n",
    "\n",
    "for dataset in datasets:\n",
    "    if dataset not in rmse_dict.keys():\n",
    "        rmse_dict[dataset] = dict()\n",
    "\n",
    "    splits = get_splits(dataset)\n",
    "    split_regex = f\"{splits}\".replace(\", \", \"|\")\n",
    "    n_splits = len(splits)\n",
    "\n",
    "    for model in models:\n",
    "        if model in rmse_dict[dataset].keys():\n",
    "            print(f\"rmse for {dataset}, {model} already exists\")\n",
    "            continue\n",
    "        \n",
    "        rmse_dict[dataset][model] = dict()\n",
    "\n",
    "        for metric in metric_keys:\n",
    "            rmse_dict[dataset][model][metric] = np.zeros((n_splits, 2))\n",
    "        \n",
    "        regex = f\"^final_{dataset}_{model}_{split_regex}.*\"\n",
    "\n",
    "        print(f\"Downloading results for {dataset}, {model}\")\n",
    "        for metric in metric_keys:\n",
    "            configs_and_metrics = load_runs_from_regex(regex, config_keys=config_keys, metric_keys=[metric])\n",
    "\n",
    "            for (configs, metrics) in configs_and_metrics:\n",
    "                split = splits.index(configs['dataset_config.split'])\n",
    "                assert model == configs['model_name']\n",
    "                # print(dataset, split, model)\n",
    "                print(metrics)\n",
    "                idx = 0 if configs['override_noise_scale'] == -1 else 1\n",
    "                rmse_dict[dataset][model][metric][split, idx] = metrics[metric][-1]\n",
    "        np.save(rmse_dict_path, rmse_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_table_filepath = \"./regression_table.tex\"\n",
    "with open(regression_table_filepath, 'w') as table:\n",
    "    table.write(\"\\\\begin{table}[]\\n\")\n",
    "    table.write(\"\\\\centering\\n\")\n",
    "    table.write(\"\\\\renewcommand{\\\\arraystretch}{1.5}\\n\")\n",
    "    table.write(\"\\\\setlength\\\\tabcolsep{2pt}\\n\")\n",
    "    table.write(\"\\\\resizebox{\\\\textwidth}{!}{%\\n\")\n",
    "    table.write(\"\\\\begin{tabular}{@{}cccclclcllclclclclclcl@{}}\\n\")\n",
    "    table.write(\"\\\\toprule\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
